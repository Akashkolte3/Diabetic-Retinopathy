# -*- coding: utf-8 -*-
"""InceptionV3 with fine Tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0tm1fSebnrRBg_mtzSKkItI_9Y3Bn5h
"""

import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input

# Define data generator without data augmentation for test set
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Load and compile pre-trained InceptionV3 model without top layer
IMG_HEIGHT = 299
IMG_WIDTH = 299
base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))

# Set the last 15 layers of the base model to be trainable
for layer in base_model.layers[:-15]:
    layer.trainable = False

# Add global average pooling and output layer to model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(5, activation='softmax') # Change 5 to the number of classes in your dataset
])

# Compile the model with categorical crossentropy loss and RMSprop optimizer
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

BATCH_SIZE = 32
IMG_SIZE = (299, 299)

# Define data directories
train_data_dir = '/content/drive/MyDrive/Final/train'
test_data_dir = '/content/drive/MyDrive/Final/test'

# Data preprocessing
# Create the test data generator with preprocessing function
test_datagen = ImageDataGenerator(
    rescale=1./255,
    preprocessing_function=preprocess_input
)

# Create the test data generator
test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    preprocessing_function=preprocess_input
)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Train the model on the training set
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=20, # Change number of epochs as needed
    verbose=1
)

# Get the predicted class for each image in the test set
preds = model.predict(test_generator)
predicted_class_indices = np.argmax(preds, axis=1)

# Map the predicted class indices to the class names
labels = {'No_DR': 0, 'Mild': 1, 'Moderate': 2, 'Severe': 3, 'Proliferate_DR': 4}
predictions = [list(labels.keys())[list(labels.values()).index(i)] for i in predicted_class_indices]

# Print the predicted class for each image in the test set
print(predictions)