# -*- coding: utf-8 -*-
"""RMS Values.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AFu2AS81nHa8YxFc9aNDib7z3XldfzkA
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import tensorflow
import keras
import os
import glob
from skimage import io
import random
import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv2
from google.colab.patches import cv2_imshow
# %matplotlib inline



"""MERGE MARTINS"""

import cv2

img_fn= ['/content/drive/MyDrive/10_left.png',
'/content/drive/MyDrive/10_right.png']
img_list = [cv2.imread(fn) for fn in img_fn]

# Exposure fusion using Mertens
mergeMertens = cv2.createMergeMertens()
resFusion = mergeMertens.process(img_list)

# Save
cv2.imwrite("fusion.png", resFusion*255)

img2 =cv2.imread('/content/fusion.png')
img1 = cv2.imread('/content/drive/MyDrive/10_left.png')
psnr = cv2.PSNR(img1, img2 )
print("PSNR value:", psnr)
# Calculate RMS value
rms_value = np.sqrt(np.mean(np.square(output_img)))
print("RMS value:", rms_value)

import cv2
import numpy as np

# Load the two RGB images
img1 = cv2.imread('/content/drive/MyDrive/10_left.png')
img2 = cv2.imread('/content/drive/MyDrive/10_right.png')

# Convert the RGB images to grayscale images
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# Calculate the Mean Gradient for each grayscale image
sobel_x = cv2.Sobel(gray1, cv2.CV_64F, 1, 0, ksize=9)
sobel_y = cv2.Sobel(gray1, cv2.CV_64F, 0, 1, ksize=9)
mean_grad1 = np.mean(np.abs(sobel_x) + np.abs(sobel_y))

sobel_x = cv2.Sobel(gray2, cv2.CV_64F, 1, 0, ksize=9)
sobel_y = cv2.Sobel(gray2, cv2.CV_64F, 0, 1, ksize=9)
mean_grad2 = np.mean(np.abs(sobel_x) + np.abs(sobel_y))

# Calculate the Spatial Frequency for each grayscale image
dft1 = cv2.dft(np.float32(gray1), flags=cv2.DFT_COMPLEX_OUTPUT)
dft2 = cv2.dft(np.float32(gray2), flags=cv2.DFT_COMPLEX_OUTPUT)
mag1 = np.sqrt(dft1[:, :, 0] ** 2 + dft1[:, :, 1] ** 2)
mag2 = np.sqrt(dft2[:, :, 0] ** 2 + dft2[:, :, 1] ** 2)
spatial_freq1 = np.mean(mag1)
spatial_freq2 = np.mean(mag2)

# Calculate the Entropy for each grayscale image
hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])
hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])
hist1_norm = hist1 / np.sum(hist1)
hist2_norm = hist2 / np.sum(hist2)
entropy1 = -np.sum(hist1_norm * np.log2(hist1_norm + 1e-7))
entropy2 = -np.sum(hist2_norm * np.log2(hist2_norm + 1e-7))

# Calculate the Standard deviation for each grayscale image
std_dev1 = np.std(gray1)
std_dev2 = np.std(gray2)

# Calculate the weights for each parameter
w_mean_grad = (mean_grad1 + mean_grad2) / 2
w_spatial_freq = (spatial_freq1 + spatial_freq2) / 2
w_entropy = (entropy1 + entropy2) / 2
w_std_dev = (std_dev1 + std_dev2) / 2

# Combine the two RGB images using the weighted average method
alpha = 0.5
beta = 1 - alpha
output = cv2.addWeighted(img1, alpha, img2, beta, 0)

# Display the output image in RGB format
cv2_imshow( output)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""GSED"""

import cv2
import numpy as np

# Load the two RGB images
img1 = cv2.imread('/content/drive/MyDrive/10_left.png')
img2 = cv2.imread('/content/drive/MyDrive/10_right.png')

# Convert the RGB images to grayscale images
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# Combine the two grayscale images using the weighted average method
alpha = 0.5
beta = 1 - alpha
gray_output = cv2.addWeighted(gray1, alpha, gray2, beta, 0)

# Calculate the RMS value of the output image
rms = np.sqrt(np.mean((gray_output - gray1) ** 2))

# Display the RMS value
print("RMS value:", rms)

import cv2
import numpy as np
import pywt
def wavelet_fusion(img1, img2):
    # Decompose the images using wavelet transform
    cA1, (cH1, cV1, cD1) = pywt.dwt2(img1, 'haar')
    cA2, (cH2, cV2, cD2) = pywt.dwt2(img2, 'haar')

    # Take the average of the approximation coefficients
    cA3 = (cA1 + cA2) / 2

    # Fuse the horizontal, vertical and diagonal detail coefficients using maximum selection rule
    cH3 = np.maximum(cH1, cH2)
    cV3 = np.maximum(cV1, cV2)
    cD3 = np.maximum(cD1, cD2)

    # Reconstruct the fused image using inverse wavelet transform
    fused_img = pywt.idwt2((cA3, (cH3, cV3, cD3)), 'haar')

    return fused_img

import cv2
import numpy as np

# Read the two input images
img1 = cv2.imread('/content/drive/MyDrive/10_left.png')
img2 = cv2.imread('/content/drive/MyDrive/10_right.png')

# Resize the images to the same size
img1 = cv2.resize(img1, (640, 480))
img2 = cv2.resize(img2, (640, 480))

# Convert the images to grayscale
img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# Perform wavelet decomposition on the two input images
level = 3  # Set the number of levels of decomposition
wavelet = 'db4'  # Set the type of wavelet
coeffs1 = pywt.wavedec2(img1_gray, wavelet, level=level)
coeffs2 = pywt.wavedec2(img2_gray, wavelet, level=level)

# Create the fused coefficients by selecting the maximum magnitude coefficients from the two input images
fused_coeffs = []
for i in range(level + 1):
    # Get the approximation and detail coefficients from the two input images
    c1 = coeffs1[i]
    c2 = coeffs2[i]

    # Create a new tuple of coefficients by selecting the maximum magnitude coefficients from the two input images
    fused_c = []
    for j in range(len(c1)):
        # Calculate the magnitudes of the coefficients from the two input images
        mag1 = np.abs(c1[j])
        mag2 = np.abs(c2[j])

        # Select the maximum magnitude coefficients
        max_mag = np.maximum(mag1, mag2)

        # Select the coefficients from the image with the maximum magnitude
        fused_c.append(np.where(max_mag == mag1, c1[j], c2[j]))

    # Add the fused coefficients to the list
    fused_coeffs.append(tuple(fused_c))

# Reconstruct the fused image from the fused coefficients
fused_img = pywt.waverec2(fused_coeffs, wavelet)

# Convert the fused image back to color (if necessary)
if len(img1.shape) == 3:
    fused_img = cv2.cvtColor(fused_img.astype('uint8'), cv2.COLOR_GRAY2BGR)

# Display the input images and the fused image
cv2_imshow(fused_img)
cv2.waitKey(0)
cv2.destroyAllWindows()


# Calculate the RMS value of the fused image
rms_value = np.sqrt(np.mean(np.square(fused_img)))

# Print the RMS value
print("RMS value of fused image:", rms_value)

"""wavelet

"""



# Calculate the RMS value of the fused image
rms_value = np.sqrt(np.mean(np.square(fused_img)))

# Print the RMS value
print("RMS value of fused image:", rms_value)

